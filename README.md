<div align="center">

# ğŸ”âœ¨ RagDocumentSearch â€” RAG minimaliste, Ã©lÃ©gant et efficace

[![Streamlit](https://img.shields.io/badge/UI-Streamlit-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io)
[![LangChain](https://img.shields.io/badge/AI-LangChain-2B5F9E)](https://python.langchain.com/)
[![LangGraph](https://img.shields.io/badge/Orchestration-LangGraph-0A84FF)](https://langchain-ai.github.io/langgraph/)
[![FAISS](https://img.shields.io/badge/Vector_DB-FAISS-12A389)](https://github.com/facebookresearch/faiss)
[![OpenAI](https://img.shields.io/badge/LLM-OpenAI-412991?logo=openai&logoColor=white)](https://platform.openai.com/)

<p>
  <img src="https://media.tenor.com/ZfGJd9q3Kk0AAAAC/anime-computer.gif" alt="anime computer" width="520"/>
</p>

</div>

> **Un moteur de recherche de documents RAG** avec une UI Streamlit. Il ingÃ¨re des pages web et des PDF locaux, indexe les chunks dans FAISS, puis orchestre un workflow LangGraph pour rÃ©cupÃ©rer le contexte pertinent et gÃ©nÃ©rer une rÃ©ponse via un LLM OpenAI.

- âœ… **SimplicitÃ©** dâ€™architecture et code lisible
- ğŸŒ **Ingestion** URL et dossier `data/` (PDF)
- ğŸ§­ **Retrieval** FAISS + OpenAI Embeddings
- ğŸ§© **Workflow** LangGraph (nÅ“uds Retrieve â†’ Respond)
- ğŸ–¥ï¸ **UI** Streamlit ergonomique et rÃ©active

---

## ğŸ—‚ï¸ Sommaire
- [PrÃ©requis](#-prÃ©requis)
- [Installation (Windows/PowerShell)](#-installation-windowspowershell)
- [Lancer lâ€™application](#-lancer-lapplication)
- [Structure du projet](#-structure-du-projet)
- [Configuration](#-configuration)
- [Flux de bout en bout (Mermaid)](#-flux-de-bout-en-bout-mermaid-vertical)
- [Architecture des composants (Mermaid)](#-architecture-des-composants-mermaid-vertical)
- [DÃ©tails techniques](#-dÃ©tails-techniques)
- [Personnaliser les sources](#-personnaliser-les-sources)
- [Conseils qualitÃ© & performance](#-conseils-qualitÃ©--performance)
- [DÃ©pannage rapide](#-dÃ©pannage-rapide)
- [Licence](#-licence)

---

## ğŸ”§ PrÃ©requis
- **Python** 3.10+
- **ClÃ© API OpenAI** dans `OPENAI_API_KEY`
- **Windows PowerShell** (les commandes fonctionnent aussi sur macOS/Linux)

---

## ğŸš€ Installation (Windows/PowerShell)

```powershell
# 1) Cloner le projet
git clone <votre-repo> ragdocumentsearchproject
cd ragdocumentsearchproject

# 2) CrÃ©er lâ€™environnement virtuel
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# 3) Installer les dÃ©pendances
pip install -r requirements.txt

# 4) Variables dâ€™environnement
# Option A: crÃ©er un fichier .env Ã  la racine
# .env
# OPENAI_API_KEY=sk-...

# Option B: exporter dans la session PowerShell
$Env:OPENAI_API_KEY = "sk-..."
```

---

## â–¶ï¸ Lancer lâ€™application

```powershell
streamlit run streamlit_app.py
```

Lâ€™interface sâ€™ouvre dans votre navigateur. Posez une question pour interroger les documents chargÃ©s.

---

## ğŸ—ï¸ Structure du projet

```
ragdocumentsearchproject/
  data/                     # PDF dâ€™exemple et sources
  src/
    config/config.py        # Config (modÃ¨le LLM, chunking, URLs par dÃ©faut)
    document_ingestion/
      document_processor.py # Chargement & split des documents
    vectorstores/vectorstore.py  # Embeddings + FAISS retriever
    state/rag_state.py      # Ã‰tat typÃ© du workflow RAG
    graph_builder/graph_builder.py # Construction du graphe LangGraph
    nodes/
      nodes.py              # NÅ“uds RAG (retrieval + rÃ©ponse LLM)
      reactnode.py          # (Variante agent ReAct + outils)
  streamlit_app.py          # UI et wiring bout-en-bout
  requirements.txt
```

---

## âš™ï¸ Configuration

Le fichier `src/config/config.py` centralise les rÃ©glages:
- **LLM_MODEL** par dÃ©faut: `openai:gpt-4o`
- **CHUNK_SIZE**, **CHUNK_OVERLAP** pour le dÃ©coupage
- **DEFAULT_URLS** pour lâ€™ingestion web initiale

Le LLM est instanciÃ© via LangChain `init_chat_model` et rÃ©cupÃ¨re la clÃ© depuis `OPENAI_API_KEY`.

---

## ğŸ”„ Flux de bout en bout (Mermaid vertical)

```mermaid
flowchart TB
    A[UI Streamlit\nstreamlit_app.py] --> B[Init LLM & Config\nConfig.get_llm()]
    A --> C[Initialize RAG\ninitialize_rag()]
    C --> D[Ingestion\nDocumentProcessor.process_url(URLs)]
    D --> E[Split en chunks\nRecursiveCharacterTextSplitter]
    E --> F[Vectorisation\nOpenAIEmbeddings]
    F --> G[Indexation FAISS\nVectorStore.create_retriever]
    G --> H[Build Graph\nGraphBuilder.build()]
    H --> I[StateGraph(RAGState)\nNodes: retriever â†’ responder]

    subgraph Query Flow
        J[Question utilisateur] --> K[Retriever.invoke(query)\nFAISS]
        K --> L[Concat contexte]
        L --> M[LLM.invoke(prompt)\nAnswer]
        M --> N[RÃ©sultat + docs sources]
    end

    A -. on submit .-> J
    I --> J
```

---

## ğŸ§± Architecture des composants (Mermaid vertical)

```mermaid
flowchart TB
    subgraph Ingestion
        DP[DocumentProcessor\nload_from_url / pdf_dir / text\nsplit_documents]
    end

    subgraph VectorStore
        VS[VectorStore\nOpenAIEmbeddings + FAISS\n.as_retriever()]
    end

    subgraph Workflow
        GB[GraphBuilder\nStateGraph<RAGState>]
        RN[RAGNode\nretriever_docs / generate_answer]
        RS[RAGState\nquery, retrieved_docs, answer]
    end

    subgraph UI
        ST[Streamlit App\ninitialize_rag, forms, history]
    end

    ST --> DP
    DP --> VS
    VS --> GB
    GB --> RN
    RN --> RS
    RS --> ST
```

---

## ğŸ› ï¸ DÃ©tails techniques

- **Ingestion**: `WebBaseLoader`, `PyPDFDirectoryLoader`, `TextLoader`
- **DÃ©coupage**: `RecursiveCharacterTextSplitter` (via `CHUNK_SIZE`, `CHUNK_OVERLAP`)
- **Indexation**: `FAISS.from_documents` + `OpenAIEmbeddings`
- **RÃ©cupÃ©ration**: `retriever.invoke(query)`
- **GÃ©nÃ©ration**: `llm.invoke(prompt)` avec un prompt contextuel minimaliste
- **Orchestration**: `langgraph.StateGraph` avec nÅ“uds `retriever` â†’ `responder`

> Option avancÃ©e: `nodes/reactnode.py` expose une variante agentique ReAct (`create_react_agent`) avec des Tools (`retriever`, `Wikipedia`).

---

## ğŸ§© Personnaliser les sources

- **URLs**: modifier `DEFAULT_URLS` dans `src/config/config.py`
- **PDF**: dÃ©poser vos fichiers dans `data/` (chargÃ©s automatiquement)
- **Textes**: support via `TextLoader` (adapter si besoin)

---

## âš¡ Conseils qualitÃ© & performance

- Ajuster `CHUNK_SIZE`/`CHUNK_OVERLAP` selon la granularitÃ© souhaitÃ©e
- Limiter la taille des PDF ou filtrer par pertinence
- Cache Streamlit dÃ©jÃ  activÃ© (`@st.cache_resource`)
- Surveiller les coÃ»ts OpenAI (embeddings + LLM)

---

## ğŸ†˜ DÃ©pannage rapide

- Erreur Â« retriever not initialized Â»: vÃ©rifier lâ€™appel Ã  `create_retriever`
- ClÃ© API: sâ€™assurer que `OPENAI_API_KEY` est bien dÃ©fini
- Ingestion: vÃ©rifier lâ€™accÃ¨s rÃ©seau et le dossier `data/`

---

## ğŸ“„ Licence
MIT (adapter si besoin)

---

<div align="center">
  <img src="https://media.tenor.com/4Zx3f6G7W9gAAAAC/anime-stars.gif" alt="anime sparkle" width="460"/>
  <br/>
  <img src="https://assets-global.website-files.com/5e4c6ab8b06f2b730b3b1bff/6298c0a0989ce5a34cba52d1_lottie-logo-animation.gif" alt="lottie" width="320"/>
  <br/>
  <sub>Made with â¤ï¸ for delightful developer experiences.</sub>
</div>
